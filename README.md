# Omega21: 5-Layer Neural Architecture

> **A Comprehensive Neural Processing System with Calibrated ONNX Models**

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Architecture: 5 Capas (Layers)](#architecture-5-capas-layers)
- [Directory Structure](#directory-structure)
- [ONNX Models](#onnx-models)
- [Calibration Parameters](#calibration-parameters)
- [Setup Instructions](#setup-instructions)
- [Usage Guide](#usage-guide)
- [Layer Details](#layer-details)

---

## Overview

**Omega21** is a sophisticated 5-layer neural architecture designed for comprehensive sensory processing and cognitive execution. The system processes information through multiple computational layers, each specialized for different aspects of neural computation and decision-making.

### Key Features

- **5-Layer Architecture**: From sensorial input to executive output
- **Calibrated Models**: Optimized for accuracy with proven AUC metrics
- **ONNX Format**: Cross-platform compatibility and deployment flexibility
- **Sensorial Foundation**: 25 atomic processing units
- **Dual Temporal-Spatial Processing**: Advanced context understanding
- **Hierarchical Association**: Multi-level pattern recognition
- **Executive Control**: Top-level decision making and output generation

---

## Architecture: 5 Capas (Layers)

### Layer Hierarchy

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Capa 5: Ejecutiva (Executive)      â”‚ â† Final Decision & Output
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Capa 4: Asociativa Superior        â”‚ â† Higher-order Associations
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Capa 3: Asociativa Inferior        â”‚ â† Lower-order Associations
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Capa 2: Dual (Temporal + Espacial) â”‚ â† Context Processing
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Capa 1: Sensorial (25 Ãtomos)      â”‚ â† Input Processing
â””â”€â”€â”€ï¿½ï¿½â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Detailed Layer Descriptions

#### **Capa 1: Sensorial (Sensory Layer)**
- **Purpose**: Primary input processing and feature extraction
- **Composition**: 25 atomic units (Ã¡tomos)
- **Function**: Converts raw input signals into standardized feature representations
- **Output**: Foundation-level feature vectors for upstream processing
- **Characteristics**: 
  - Direct input reception
  - Basic feature normalization
  - Signal amplitude calibration

#### **Capa 2: Dual (Temporal + Espacial)**
- **Purpose**: Context understanding through dual-axis processing
- **Composition**: Temporal pathway + Spatial pathway
- **Temporal Component**: 
  - Processes sequential patterns
  - Maintains temporal dependencies
  - Context window management
- **Spatial Component**: 
  - Processes spatial relationships
  - Multi-dimensional pattern analysis
  - Spatial context integration
- **Output**: Enriched feature representations with temporal and spatial context

#### **Capa 3: Asociativa Inferior (Lower Associative Layer)**
- **Purpose**: Primary pattern association and basic relationships
- **Function**: Identifies recurring patterns and direct associations
- **Characteristics**:
  - Local pattern recognition
  - Direct feature correlations
  - Foundation for higher-order abstractions
- **Output**: Basic association patterns and feature groups

#### **Capa 4: Asociativa Superior (Upper Associative Layer)**
- **Purpose**: Complex pattern recognition and abstract concept formation
- **Function**: Integrates lower associations into comprehensive patterns
- **Characteristics**:
  - Cross-modal integration
  - Complex relationship mapping
  - Abstract concept generation
- **Output**: High-level conceptual representations

#### **Capa 5: Ejecutiva (Executive Layer)**
- **Purpose**: Final decision making and output generation
- **Function**: Synthesizes all previous layers into actionable decisions
- **Characteristics**:
  - Output gate control
  - Final classification/prediction
  - Executive decision making
- **Output**: Final model output, predictions, or decisions

---

## Directory Structure

```
jupiter-/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ best_omega21.onnx             # Calibrated model (RECOMMENDED)
â”‚   â”œâ”€â”€ omega21_brain.onnx            # Atom-based model
â”‚   â””â”€â”€ calibration_info.txt          # Calibration metadata
â”œâ”€â”€ calibration/
â”‚   â”œâ”€â”€ calibration_params.json       # Calibration parameters
â”‚   â”œâ”€â”€ calibration_log.txt           # Calibration process log
â”‚   â””â”€â”€ performance_metrics.json      # Model performance metrics
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ omega21.py                    # Main Omega21 implementation
â”‚   â”œâ”€â”€ loader.py                     # ONNX model loader
â”‚   â””â”€â”€ utils.py                      # Utility functions
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_models.py                # Model testing suite
â”‚   â””â”€â”€ test_layers.py                # Layer-specific tests
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ basic_inference.py            # Basic usage example
â”‚   â”œâ”€â”€ batch_processing.py           # Batch processing example
â”‚   â””â”€â”€ layer_visualization.py        # Visualize layer outputs
â””â”€â”€ requirements.txt                  # Python dependencies
```

---

## ONNX Models

### **best_omega21.onnx** (Recommended)

**Status**: Fully Calibrated & Optimized

- **File**: `models/best_omega21.onnx`
- **Model Type**: Complete 5-layer neural system
- **Optimization Level**: Full
- **Intended Use**: Production inference, real-world applications
- **Performance Metrics**:
  - AUC: **0.841634**
  - Calibration Scale: **-0.38**
  - Calibration Offset: **0.42**

**When to Use**:
- âœ… Production deployments
- âœ… High-accuracy predictions required
- âœ… Cross-platform compatibility needed
- âœ… Resource-constrained environments

**Characteristics**:
- Fully optimized for inference speed
- Pre-calibrated with proven parameters
- Balanced accuracy and computational efficiency
- Recommended for most use cases

---

### **omega21_brain.onnx** (Atom-Based)

**Status**: Foundational Atom Model

- **File**: `models/omega21_brain.onnx`
- **Model Type**: Atom-level processing (Capa 1 foundation)
- **Architecture**: 25 atomic processing units
- **Intended Use**: Research, layer-by-layer analysis, fine-tuning

**When to Use**:
- ğŸ“š Research and development
- ğŸ” Layer-by-layer analysis
- ğŸ“ Learning the architecture
- ğŸ”§ Custom fine-tuning scenarios

**Characteristics**:
- Direct access to atomic features
- Lower-level computational control
- Useful for understanding sensorial processing
- Foundation for building custom architectures

---

## Calibration Parameters

### **Standard Calibration (Applied to best_omega21.onnx)**

```json
{
  "calibration_scale": -0.38,
  "calibration_offset": 0.42,
  "auc_score": 0.841634,
  "calibration_method": "Platt Scaling",
  "applied_date": "2026-01-06",
  "validation_set_size": 0.2,
  "confidence": "High"
}
```

### What These Parameters Mean

- **Calibration Scale (-0.38)**: Adjusts the slope of the model's output mapping
  - Negative value indicates probability redistribution
  - Refines decision boundary sharpness
  
- **Calibration Offset (0.42)**: Adjusts the intercept of the output mapping
  - Shifts probability estimates for improved accuracy
  - Ensures well-calibrated confidence scores
  
- **AUC Score (0.841634)**: Area Under the ROC Curve
  - Measures discrimination ability across probability thresholds
  - Range: 0-1 (1.0 = perfect classification)
  - 0.84+ indicates excellent discrimination

### How Calibration is Applied

```
Raw Output: y_raw
Calibrated Output: y_calibrated = scale * y_raw + offset
                  = -0.38 * y_raw + 0.42
```

---

## Setup Instructions

### Prerequisites

- Python 3.7 or higher
- pip package manager
- ONNX Runtime

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/Ell1Ot-rgb/jupiter-.git
   cd jupiter-
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Verify ONNX models**
   ```bash
   python src/loader.py --verify
   ```

### Required Dependencies

```
onnx>=1.12.0
onnxruntime>=1.13.0
numpy>=1.21.0
pandas>=1.3.0
scikit-learn>=1.0.0
```

---

## Usage Guide

### Basic Inference with best_omega21.onnx

```python
import onnxruntime as rt
import numpy as np

# Load the calibrated model
sess = rt.InferenceSession("models/best_omega21.onnx")

# Prepare input data (shape depends on your input specification)
# Example: batch of 32 samples with 128 features
input_data = np.random.randn(32, 128).astype(np.float32)

# Get input name
input_name = sess.get_inputs()[0].name

# Run inference
output = sess.run(None, {input_name: input_data})

# Output contains predictions with applied calibration
predictions = output[0]
print(f"Predictions shape: {predictions.shape}")
print(f"First prediction: {predictions[0]}")
```

### Using omega21_brain.onnx (Atom-Based)

```python
import onnxruntime as rt
import numpy as np

# Load the atom-based model
sess = rt.InferenceSession("models/omega21_brain.onnx")

# Prepare input data
input_data = np.random.randn(1, 128).astype(np.float32)

# Get input name
input_name = sess.get_inputs()[0].name

# Run inference to get atomic features
atom_features = sess.run(None, {input_name: input_data})

# Analyze 25 atomic units from Capa 1
atoms = atom_features[0]
print(f"Number of atomic units: {atoms.shape[1]}")
print(f"Atomic activations: {atoms[0]}")

# Access specific atoms for custom processing
atom_1_activation = atoms[0, 0]
atom_25_activation = atoms[0, 24]
```

### Batch Processing

```python
import onnxruntime as rt
import numpy as np

# Load model
sess = rt.InferenceSession("models/best_omega21.onnx")
input_name = sess.get_inputs()[0].name

# Process multiple batches
def batch_inference(data_generator, batch_size=32):
    for batch in data_generator:
        # Ensure correct shape
        batch = np.array(batch, dtype=np.float32)
        
        # Run inference
        predictions = sess.run(None, {input_name: batch})[0]
        
        yield predictions

# Use in your data pipeline
for predictions in batch_inference(data_loader):
    # Process predictions
    print(f"Batch predictions: {predictions.shape}")
```

### Layer-by-Layer Analysis

```python
import onnxruntime as rt
import numpy as np

def analyze_layers(input_data, model_path="models/omega21_brain.onnx"):
    """
    Analyze the activation of each layer
    """
    sess = rt.InferenceSession(model_path)
    
    # Get all input/output node information
    print("=== Layer Information ===")
    print(f"\nInputs:")
    for inp in sess.get_inputs():
        print(f"  - {inp.name}: {inp.shape} (type: {inp.type})")
    
    print(f"\nOutputs:")
    for out in sess.get_outputs():
        print(f"  - {out.name}: {out.shape} (type: {out.type})")
    
    # Run inference
    input_name = sess.get_inputs()[0].name
    outputs = sess.run(None, {input_name: input_data})
    
    return outputs
```

---

## Layer Details & Processing Flow

### Complete Processing Pipeline

```
INPUT DATA
    â†“
    â”œâ”€â†’ Capa 1: Sensorial (25 Ãtomos)
    â”‚   â”œâ”€ Signal Reception
    â”‚   â”œâ”€ Atomic Feature Extraction (25 units)
    â”‚   â””â”€ Normalization
    â†“
    â”œâ”€â†’ Capa 2: Dual Processing
    â”‚   â”œâ”€ Temporal Pathway
    â”‚   â”‚   â””â”€ Sequence Analysis
    â”‚   â””â”€ Spatial Pathway
    â”‚       â””â”€ Relationship Analysis
    â†“
    â”œâ”€â†’ Capa 3: Asociativa Inferior
    â”‚   â”œâ”€ Pattern Recognition
    â”‚   â””â”€ Direct Feature Associations
    â†“
    â”œâ”€â†’ Capa 4: Asociativa Superior
    â”‚   â”œâ”€ Complex Pattern Integration
    â”‚   â””â”€ Abstract Concept Formation
    â†“
    â”œâ”€â†’ Capa 5: Ejecutiva
    â”‚   â”œâ”€ Decision Synthesis
    â”‚   â””â”€ Output Generation
    â†“
OUTPUT (with Calibration Applied)
```

### Data Flow Within Each Layer

**Capa 1**: Raw Input â†’ 25 Atomic Features
- Input dimension: Flexible (depends on your data)
- Output dimension: 25 features
- Processing: Sensorial encoding

**Capa 2**: Atomic Features â†’ Temporal-Spatial Context
- Input: 25 atomic features
- Processing: Dual pathway (temporal & spatial)
- Output: Context-enriched features

**Capa 3**: Context Features â†’ Associated Patterns
- Input: Temporal-spatial representations
- Processing: Pattern association
- Output: Local pattern clusters

**Capa 4**: Pattern Clusters â†’ Abstract Concepts
- Input: Associated patterns
- Processing: Higher-order integration
- Output: Conceptual representations

**Capa 5**: Concepts â†’ Final Decision
- Input: Conceptual representations
- Processing: Executive synthesis
- Output: Final prediction/decision
- Post-processing: Calibration applied

---

## Performance Metrics

### Model Evaluation Results

| Metric | Value |
|--------|-------|
| **AUC (ROC)** | 0.841634 |
| **Calibration Scale** | -0.38 |
| **Calibration Offset** | 0.42 |
| **Calibration Method** | Platt Scaling |
| **Recommended Threshold** | 0.5 |

### Interpretation

- **High AUC (0.84+)**: Model has excellent discrimination ability
- **Calibrated Parameters**: Probability outputs can be trusted
- **Ready for Production**: All metrics indicate production-ready status

---

## Advanced Usage

### Custom Input Preprocessing

```python
import numpy as np
from src.utils import preprocess_input

# Load and preprocess your data
raw_data = np.load('your_data.npy')
preprocessed = preprocess_input(raw_data)

# Use with model
predictions = sess.run(None, {input_name: preprocessed})
```

### Model Ensemble (best_omega21 + omega21_brain)

```python
import onnxruntime as rt
import numpy as np

# Load both models
model_best = rt.InferenceSession("models/best_omega21.onnx")
model_atoms = rt.InferenceSession("models/omega21_brain.onnx")

# Get predictions from both
input_name_best = model_best.get_inputs()[0].name
input_name_atoms = model_atoms.get_inputs()[0].name

pred_best = model_best.run(None, {input_name_best: data})[0]
pred_atoms = model_atoms.run(None, {input_name_atoms: data})[0]

# Ensemble predictions (average)
ensemble_pred = (pred_best + np.mean(pred_atoms, axis=1, keepdims=True)) / 2
```

---

## Troubleshooting

### Model Loading Issues

**Problem**: "Session creation failed"
```
Solution: Ensure ONNX Runtime is installed
pip install --upgrade onnxruntime
```

**Problem**: "Input shape mismatch"
```
Solution: Check your input data shape matches model expectations
Print model input shape:
  sess.get_inputs()[0].shape
```

### Performance Optimization

- Use batch processing for better throughput
- Ensure input data is float32 format
- Pre-allocate numpy arrays when possible
- Consider using GPU execution provider for larger batches

---

## Citation & References

**Omega21 Architecture**
```
Title: Omega21 - Five-Layer Neural Processing System
Calibration Date: 2026-01-06
Model Type: Multi-layer Associative Network
AUC Performance: 0.841634
```

---

## Contributing

Contributions are welcome! Please ensure:
- Code follows existing style
- All tests pass (`pytest tests/`)
- Documentation is updated
- Calibration parameters are preserved in production models

---

## License

This project is licensed under the MIT License - see LICENSE file for details.

---

## Support & Contact

For issues, questions, or feature requests:
- GitHub Issues: [Create an issue](https://github.com/Ell1Ot-rgb/jupiter-/issues)
- Author: Ell1Ot-rgb

---

**Last Updated**: 2026-01-06  
**Omega21 Version**: 1.0.0  
**Model Status**: Production Ready âœ…
